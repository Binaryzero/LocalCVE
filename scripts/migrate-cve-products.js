#!/usr/bin/env node
/**
 * Migration script to populate the cve_products table from existing configs data.
 * Uses batched inserts and fresh connections to avoid DuckDB stability issues.
 */

import { DuckDBInstance } from '@duckdb/node-api';
import path from 'path';

const dbPath = path.resolve(process.cwd(), 'cve.duckdb');
const BATCH_SIZE = 5000;
const INSERT_BATCH_SIZE = 500;

async function migrate() {
    console.log('Connecting to DuckDB...');
    const instance = await DuckDBInstance.create(dbPath);
    let conn = await instance.connect();

    try {
        // Check if cve_products table exists
        const tables = await conn.runAndReadAll(
            "SELECT table_name FROM information_schema.tables WHERE table_name = 'cve_products'"
        );
        if (tables.getRowObjects().length === 0) {
            console.log('Creating cve_products table...');
            await conn.run(`
                CREATE TABLE IF NOT EXISTS cve_products (
                    cve_id VARCHAR NOT NULL,
                    vendor VARCHAR NOT NULL,
                    product VARCHAR NOT NULL
                )
            `);
            await conn.run('CREATE INDEX IF NOT EXISTS idx_cve_products_cve ON cve_products(cve_id)');
            await conn.run('CREATE INDEX IF NOT EXISTS idx_cve_products_vendor ON cve_products(vendor)');
            await conn.run('CREATE INDEX IF NOT EXISTS idx_cve_products_product ON cve_products(product)');
        }

        // Get total count
        const countResult = await conn.runAndReadAll('SELECT COUNT(*) as cnt FROM configs');
        const totalCount = Number(countResult.getRowObjects()[0].cnt);
        console.log(`Total configs rows: ${totalCount}`);

        // Check current state (for resume capability)
        const existingCount = await conn.runAndReadAll('SELECT COUNT(*) as cnt FROM cve_products');
        const existingRows = Number(existingCount.getRowObjects()[0].cnt);
        console.log(`Current cve_products rows: ${existingRows}`);

        // Find where to resume from (get max cve_id already processed)
        let startOffset = 0;
        if (existingRows > 0) {
            console.log(`Resuming from existing state...`);
            // Clear and restart - can't reliably resume with ORDER BY
            await conn.run('DELETE FROM cve_products');
        }

        console.log('Migrating configs to cve_products...');
        let offset = startOffset;
        let totalInserted = 0;
        let pendingInserts = [];

        async function flushInserts() {
            if (pendingInserts.length === 0) return;

            // Build multi-row INSERT
            const values = pendingInserts.map((_, i) => `($${i*3+1}, $${i*3+2}, $${i*3+3})`).join(',');
            const params = {};
            pendingInserts.forEach((p, i) => {
                params[i*3+1] = p.cve_id;
                params[i*3+2] = p.vendor;
                params[i*3+3] = p.product;
            });

            await conn.run(`INSERT INTO cve_products (cve_id, vendor, product) VALUES ${values}`, params);
            totalInserted += pendingInserts.length;
            pendingInserts = [];
        }

        while (offset < totalCount) {
            // Fetch batch of configs
            const batchResult = await conn.runAndReadAll(
                `SELECT cve_id, nodes FROM configs ORDER BY cve_id LIMIT ${BATCH_SIZE} OFFSET ${offset}`
            );
            const rows = batchResult.getRowObjects();

            if (rows.length === 0) break;

            for (const row of rows) {
                try {
                    const nodes = JSON.parse(row.nodes);
                    const seenProducts = new Set();

                    for (const config of nodes) {
                        const vendor = config.vendor || 'n/a';
                        const product = config.product || 'n/a';
                        const key = `${vendor}|${product}`;

                        if (!seenProducts.has(key) && vendor !== 'n/a' && product !== 'n/a') {
                            seenProducts.add(key);
                            pendingInserts.push({ cve_id: row.cve_id, vendor, product });

                            if (pendingInserts.length >= INSERT_BATCH_SIZE) {
                                await flushInserts();
                            }
                        }
                    }
                } catch (e) {
                    console.error(`Error processing ${row.cve_id}:`, e.message);
                }
            }

            offset += rows.length;
            const percent = Math.round((offset / totalCount) * 100);
            process.stdout.write(`\rProcessed ${offset}/${totalCount} (${percent}%) - ${totalInserted + pendingInserts.length} products`);
        }

        // Flush remaining inserts
        await flushInserts();

        console.log(`\nMigration complete! Inserted ${totalInserted} rows into cve_products.`);

        // Verify
        const finalCount = await conn.runAndReadAll('SELECT COUNT(*) as cnt FROM cve_products');
        console.log(`Final cve_products count: ${Number(finalCount.getRowObjects()[0].cnt)}`);

    } catch (err) {
        console.error('Migration error:', err);
        throw err;
    }
}

migrate()
    .then(() => process.exit(0))
    .catch((err) => {
        console.error(err);
        process.exit(1);
    });
